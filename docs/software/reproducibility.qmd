---
title: "Reproducibility"
format: html
---

Reproducibility refers to the ability to obtain consistent results when using the same data, methods, and analyses. Ensuring that our work is reproducible is essential—not only so that our findings can be verified by ourselves and by external researchers, but also to facilitate transparency and credibility. A reproducible workflow also makes it easier to repurpose parts of the code for other projects, saving time and reducing the likelihood of introducing errors.

Here we discuss two ways to enhance the reproducibility of the analysis:

1.  **organizing the code base in a logical sequence of scripts**, and\
2.  **package management**.

------------------------------------------------------------------------

## Project script structure

For reproducibility, it is important to break down the project workflow into a logical sequence of scripts and clearly document the order in which they should be executed. We recommend the following practices:

### Split a code base into multiple scripts

Breaking a project into a series of scripts makes it easier to test, maintain, and reuse code compared to working in a single monolithic file. While there is no strict rule for how to divide code, the following are good practices:

-   **Focus on one substantial responsibility per script.**\
    Each script should perform a clearly defined task, such as pre-processing a large dataset, creating geographical overlays, merging supplementary datasets, generating descriptive statistics, or running a specific analysis.

-   **Separate time-consuming steps.**\
    If a procedure is computationally expensive, place it in its own script and save the output as an intermediate dataset for later steps. This avoids unnecessarily re-running lengthy processes, such as complex geospatial calculations or aggregating large datasets.

-   **Isolate key intermediate outputs.**\
    If a block of code produces an output that will be used in multiple subsequent steps, place it in a dedicated script and save the output for reuse.

-   **Extract reusable code blocks.**\
    If a section of code—such as a function—is repeated across multiple scripts, centralize it (along with the required libraries) in a single location. The code block or function can then be sourced or imported from other scripts. For example:

    -   *In R:* `source("script_name.R")`\
    -   *In Python:* `import module_name`\
    -   *In Stata:* `do filename.do`

### Number scripts and script folders

Script names can begin with a two-digit number (e.g., `00_`, `01_`, `02_`) to encode execution order. When a folder is sorted by name, the scripts appear in the intended run sequence. For steps that can run in parallel, append letters (e.g., `01a_`, `01b_`, `01c_`).

Apply the same scheme to folders (e.g., `00_setup`, `01_processing`, `02_analysis`) so dependencies are clear—for example, cleaning steps run before analysis.

An example of this structure is provided below.

#### Example Script Folder

```         
scripts/
|--00_tools/                          # Shared helpers, not part of pipeline
|   |--filters.R                      # Reusable filter functions
|   |--data_io.R                      # Reusable input/output wrapper functions
|
|--01_processing/                     # Data prep and integration
|   |--01_clean.R                     # Clean raw data
|   |--02_aggregate.R                 # Aggregate to analysis unit
|   |--03_merge_external.R            # Merge with supplementary datasets
|
|--02_analysis/                       # Analysis and outputs
|   |--01a_summary_stats.R            # Summary statistics
|   |--01b_map.R                      # Descriptive spatial visualizations
|   |--01c_time_series_figure.R       # Descriptive time series plots
|   |--02_main_regressions.R          # Main statistical analysis
|   |--03_robustness_checks.R         # Alternative specifications
```

### Create a `run_all` script

A `run_all` script executes all other scripts in the project in the correct order. This script documents the full workflow and can be used to reproduce the project’s complete set of outputs, including intermediate data products and final results, starting from the raw data.

When using script numbering together with a `run_all` script, it is important to keep both up to date whenever new scripts are added or existing scripts are reorganized.

If the project uses global parameters referenced across multiple scripts, place them in a dedicated configuration script and load that script at the beginning of the `run_all` file.

#### Example `run_all.R` Script

``` r
# This script runs all the code in my project, from scratch

# Prepare analysis data
source("scripts/01_processing/01_clean.R")                    
source("scripts/01_processing/02_aggregate.R")       
source("scripts/01_processing/03_merge_external.R")

# Descriptive stats and figures
source("scripts/02_analysis/01a_summary_stats.R")                    
source("scripts/02_analysis/01b_map.R")       
source("scripts/02_analysis/01c_time_series_figure.R")

# Analysis
source("scripts/02_analysis/02_main_regressions.R")
source("scripts/02_analysis/03_robustness_checks.R")
```

------------------------------------------------------------------------

## Package management

An analysis using the same code and data may not run identically across different machines if the machines have different operating systems, application versions, or package versions installed. Therefore, package management is a critical component of reproducibility.

Virtual environments provide a way to isolate the software dependencies of a project, such as package versions and system libraries, so that they are consistent over time and independent of other projects on the same machine. Maintaining separate environments for different projects prevents conflicts between dependencies, allows older analyses to remain reproducible even as packages evolve, and supports collaborative work by ensuring that all contributors run the code under the same computational conditions.

Three common tools for managing computational environments are **renv**, **conda** and **Docker**.

-   **renv** (for R) creates project-specific environments that record and restore the exact package versions used in an analysis. This ensures that results can be reproduced even if packages have been updated globally.

-   **conda** (for Python, R, and other languages) manages project-specific environments by explicitly specifying package versions and system dependencies. conda helps ensure that analyses run consistently across machines and over time, particularly for workflows that rely on compiled libraries or mixed-language dependencies.

-   **Docker** goes further by packaging the entire computational environment (including the operating system and versions of R, Python, Julia, and all associated packages) into a self-contained container that can be run on any machine.

At this time, the working group has not fully tested the functionality of these tools. The resources listed below are provided for reference. We would love to hear from users who have implemented any of these tools in RFF’s computing environment. Please [get in touch with us](../../index.qmd#questions-and-feedback) to share your experience. 

#### renv

-   [Introduction to renv](https://rstudio.github.io/renv/articles/renv.html){target="_blank" rel="noopener"}
-   Video walkthrough: [Using renv to track the version of your packages in R](https://www.youtube.com/watch?v=yc7ZB4F_dc0){target="_blank" rel="noopener"}
-   [RStudio user guide: renv](https://docs.posit.co/ide/user/ide/guide/environments/r/renv.html){target="_blank" rel="noopener"}

#### conda

-   [Getting started with conda](https://docs.conda.io/projects/conda/en/stable/user-guide/getting-started.html){target="_blank" rel="noopener"}
-   [Managing environments](http://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html){target="_blank" rel="noopener"}
-   Lesson by the Carpentries Incubator: [Introduction to Conda for (Data) Scientists](https://carpentries-incubator.github.io/introduction-to-conda-for-data-scientists/){target="_blank" rel="noopener"}

#### Docker

-   [Docker 101 Tutorial](https://www.docker.com/101-tutorial/){target="_blank" rel="noopener"}
-   [Get started: Introduction](https://docs.docker.com/get-started/introduction/){target="_blank" rel="noopener"}
-   [Use of Docker for Reproducibility in Economics](https://aeadataeditor.github.io/posts/2021-11-16-docker){target="_blank" rel="noopener"}


<!--
While both tools enhance reproducibility, **we recommend renv for projects that primarily use R**. Below is a quick guide for **renv**.


### renv overview

The **renv** package helps create reproducible, isolated environments for R projects. (In this guide, a *project* refers to a working directory managed by renv. If using RStudio, this usually corresponds to an RStudio Project, but renv also works outside of RStudio.) With **renv**, each project has its own isolated package library, so different projects can use different package versions without interfering with each other. This isolation, combined with lockfiles and restore tools, makes it easier to share, reproduce, and maintain your analyses over time.

### The package environment

- A **package** is a collection of R functions and data (e.g., **dplyr**).
- A **package library** is a folder that stores installed packages. By default, R uses one system-level package library for everything. With **renv**, each project has its own package library.
- A **package repository** is where packages are obtained (e.g., CRAN, GitHub).

Check your current R package environment:

```r
.libPaths()        # active package library paths
getOption("repos") # package repositories
```


### Initial setup  
*To be done once per project, by one person.*

#### 1. Install renv and set the working directory

In RStudio, set the working directory to the project repository, then install renv (installation is required once per machine):

```r
install.packages("renv")
```

#### 2. Initialize renv in the project

```r
renv::init()
```

Initialization creates the following folders and files in the project directory:

- `renv/library/` — project-specific package library  
- `renv.lock` — records exact package versions  
- `.Rprofile` — automatically activates **renv** whenever this project is opened  


#### 3. Configure the package library for better performance

Project folders containing data and code should be stored on the `L:/` drive. By default, renv creates a project-level package library within the project folder. However, accessing packages on a network drive can slow down R performance, especially when working remotely. To improve performance, we recommend that all project users configure **renv** to store the package library on their local or lab machine: 

- Redirect the project’s library to a local drive by creating a new text file in the project folder called `.Renviron` (no .txt extension). Insert the text below into the text file. This may need to be repeated on individual lab machines.

```r
RENV_PATHS_LIBRARY=C:/Users/<username>/renv_libs
```

- Restart RStudio and confirm the active package library path using:

```r
.libPaths()
```

#### 4. Install required packages


```r 
renv::install("tidyverse") 
```

#### 5. Save loaded package versions to the lock file
```r 
renv::snapshot()
```

#### 6. Commit to version control

Commit `renv.lock`, `.Rprofile`, and `.gitignore` to version control. Do not commit `renv/library/` or `.Renviron` to version control (add these to the `.gitignore` file if necessary).


### User / machine setup

*This step is completed after a renv library has been set up for the project. All project users should complete this step the first time they use renv on a given machine.*

#### 1. Open the project in RStudio 
This can be done by setting the working directory or by opening the R project `.prj` file.

#### 2. Install the packages in the renv library

```r 
renv::restore() 
```

This installs the exact package versions recorded in the lockfile.

#### 3. Configure the project to store the package library locally to improve performance

Redirect the project’s library to a local drive by adding a `.Renviron` file (no extension) to the project folder containing the following text. This may need to be repeated on individual lab machines.
```r 
RENV_PATHS_LIBRARY=C:/Users/<username>/renv_libs 
```

Restart RStudio and confirm the new package environment with:
```r 
.libPaths() 
```

Do not commit changes to `.Renviron` to git.


### Adding a new package to the project

#### 1. Install the package

You can use renv’s install function or the base function to install the package. Specify the desired version if necessary.

```r
renv::install(“packagename”) 
```
or 
```r
install.packages(“packagename”) 
```

#### 2. Load the package 

```r
library(packagename)
```
Make sure the package works as expected in your script.


#### 3. Update the lockfile

```r
renv::snapshot()
```
This step records the package and its version in the lockfile.

#### 4. Commit to version control 
Commit changes made to scripts and `renv.lock` (lock file) to version control. Next time other users pull your changes to the repository, they will include metadata on the specific package you used.


### Resolving version conflicts / reproducibility issues

Sometimes conflicts will arise. For example, a package update may cause one script to work correctly while breaking another. If this happens, take the following steps.

#### 1. Detect the issue
Run the failing script to confirm.

Check mismatches between lockfile and installed packages:
```r 
renv::status() 
```

#### 2. Identify past snapshot
Use Git history to check the commit where the script last worked and inspect the `renv.lock` file changes at that commit. Alternatively, run the following command to see past lockfile status:
```r 
renv::history() 
```

#### 3. (Optional) Test older environment to identify compatible package versions

Revert to previous library versions:
```r
renv::revert(commit = “<commit_hash>”)
Renv::restore()
```
Check if the old script runs correctly, and test whether the newer script can run on the older package.

#### 4. Choose a resolution path
Options:

- If both scripts can run on the older package, revert to that package version in lockfile and update the snapshot.
- Keep the newer package, and document that the old script depends on a previous environment.
- Update older script to be compatible.

#### 5. Document and commit

Record which scripts depend on which versions. Commit updated `renv.lock` (if keeping the new environment).


### Additional resources

#### Basics
- [Introduction to renv](https://rstudio.github.io/renv/articles/renv.html){target="_blank" rel="noopener"}
-   Video walkthrough: [Using renv to track the version of your packages in R](https://www.youtube.com/watch?v=yc7ZB4F_dc0){target="_blank" rel="noopener"}
-   [RStudio user guide: renv](https://docs.posit.co/ide/user/ide/guide/environments/r/renv.html){target="_blank" rel="noopener"}
-   [Frequently asked questions](https://rstudio.github.io/renv/articles/faq.html){target="_blank" rel="noopener"}

####    Handling conflicts
-   [View and revert to a historical lockfile](https://rstudio.github.io/renv/reference/history.html){target="_blank" rel="noopener"}
-   [Report inconsistencies between lockfile, library, and dependencies](https://rstudio.github.io/renv/reference/status){target="_blank" rel="noopener"}

#### Uninstall renv
- [How to uninstall renv from your project](https://rstudio.github.io/renv/articles/renv.html#uninstalling-renv){target="_blank" rel="noopener"}

-->

